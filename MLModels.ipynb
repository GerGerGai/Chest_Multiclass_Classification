{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1anEhwcWT8IMDk8IT9RAPELUbc7pCnBO7","timestamp":1737680369540}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PUZDg9zliSj","executionInfo":{"status":"ok","timestamp":1737677727841,"user_tz":480,"elapsed":1053,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"5837ba50-ec76-434d-b7f0-e7062dd549da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Chest_Multiclass_Classification'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (3/3), done.\n"]}]},{"cell_type":"code","source":["%cd Chest_Multiclass_Classification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICKC0s5JlvP0","executionInfo":{"status":"ok","timestamp":1737676501298,"user_tz":480,"elapsed":4,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"a40d3917-3567-4545-c819-96c8b3430173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Chest_Multiclass_Classification\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7lLVgAVQaKaT"},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","from torch import nn  # nn contains all of PyTorch's building blocks for neural networks\n","from torch.utils.data import DataLoader # we need DataLoader to feed image into model\n","import matplotlib.pyplot as plt\n","\n","from torchvision import datasets, transforms\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))"]},{"cell_type":"code","source":["# helper function to show an image\n","\n","def imshow(image, ax=None, title=None, normalize=True):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    if ax is None:\n","        fig, ax = plt.subplots()\n","    image = image.numpy().transpose((1, 2, 0))\n","\n","    if normalize:\n","        mean = np.array([0.485, 0.456, 0.406])\n","        std = np.array([0.229, 0.224, 0.225])\n","        image = std * image + mean\n","        image = np.clip(image, 0, 1)\n","\n","    ax.imshow(image)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    ax.tick_params(axis='both', length=0)\n","    ax.set_xticklabels('')\n","    ax.set_yticklabels('')\n","\n","    return ax"],"metadata":{"id":"Kowuf4FoaciI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Configure the device to use GPU if available..."],"metadata":{"id":"OvH1y32Oanie"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0KRg23baoNR","executionInfo":{"status":"ok","timestamp":1737664569999,"user_tz":480,"elapsed":329,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"1283beb5-f4d4-4ed4-f6cb-48a85112acd1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### First, we need to construct some transforms we want to apply to our images (compression of channels and lower dimension?)####"],"metadata":{"id":"ZjBMJiO9bHkP"}},{"cell_type":"code","source":["### LOAD THE IMAGE DATA\n","transform = transforms.Compose([transforms.Resize((256,256)),\n","                                transforms.Grayscale(num_output_channels=1),\n","                                transforms.ToTensor()])"],"metadata":{"id":"P4p3ccRbaqWT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Now we can load the images and split them into train validation test sets while applying the transforms we just constructed... ####"],"metadata":{"id":"6YWDxOSGcIOc"}},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/Chest Tomography Classifier/data'\n","\n","TRAIN_PATH = PATH + '/train'\n","training_set = datasets.ImageFolder(TRAIN_PATH, transform=transform)\n","training_loader = DataLoader(training_set, batch_size=32, shuffle=True)\n","\n","VAL_PATH = PATH + '/val'\n","validation_set = datasets.ImageFolder(VAL_PATH, transform=transform)\n","validation_loader = DataLoader(validation_set, batch_size=32, shuffle=True)\n","\n","TEST_PATH = PATH + '/test'\n","testing_set = datasets.ImageFolder(TEST_PATH, transform=transform)\n","testing_loader = DataLoader(testing_set, batch_size=32, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"Fo2erHYDbBOg","executionInfo":{"status":"error","timestamp":1737664614367,"user_tz":480,"elapsed":327,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"570ec882-010a-4aee-ae99-1f673e1e246d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Chest Tomography Classifier/data/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-264c9ee6ba01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTRAIN_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtraining_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Chest Tomography Classifier/data/train'"]}]},{"cell_type":"code","source":["# Run this to test our training data loader\n","images, labels = next(iter(training_loader))\n","# helper.imshow(images[0], normalize=False)\n","imshow(images[0], normalize=False)\n","images[0].shape"],"metadata":{"id":"H0DaVzpWh9E_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Let's do some EDA"],"metadata":{"id":"dNewK8ddmhNQ"}},{"cell_type":"code","source":["# shape of the image batch and the labels batch\n","images.shape, labels.shape"],"metadata":{"id":"FbPh32zamfZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Shape of datasets\n","print(f\"Number of samples of training set: {len(training_set)}\")\n","print(f\"Number of samples of validation set: {len(validation_set)}\")\n","print(f\"Number of samples of test set: {len(testing_set)}\")"],"metadata":{"id":"bdBT9K_Amjbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classes\n","\n","unique_class = training_set.classes\n","unique_class"],"metadata":{"id":"FpfYy7E1mkzc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Now we can start building our model. We will first build a simple baseline model, which will be used as a baseline to compare the results of later models to. We then will build more complex models to try to find the model with the best performance, which could include neural network models without/with non-linearity, CNNs and ResNet.¶"],"metadata":{"id":"LgJ5jPB-moTK"}},{"cell_type":"markdown","source":["# 1. Build baseline model"],"metadata":{"id":"bgnzr0f5mtMq"}},{"cell_type":"markdown","source":["## 1.1 Create a timer function"],"metadata":{"id":"2Mi5y28-murc"}},{"cell_type":"code","source":["from timeit import default_timer as timer\n","\n","def train_time(start: float, end: float, device: torch.device = None):\n","\n","    total_time = end - start\n","    print(f\"Train time on {device}: {total_time: .4f} seconds\")\n","\n","    return total_time"],"metadata":{"id":"SxC6GEVXmpZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Baseline Model"],"metadata":{"id":"p_349n1cmz64"}},{"cell_type":"code","source":["class BaseModel0(nn.Module):\n","    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n","        super().__init__()\n","        self.layer_stack = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features = input_shape, out_features = hidden_units),\n","            nn.Linear(in_features = hidden_units, out_features = hidden_units),\n","            nn.Linear(in_features = hidden_units, out_features = output_shape)\n","        )\n","\n","    def forward(self, x):\n","        return self.layer_stack(x)"],"metadata":{"id":"PuXCpsRCmyJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseModel = BaseModel0(input_shape = 256*256, hidden_units = 100, output_shape = len(unique_class))\n","\n","baseModel.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"uLCvfu2Nm1iB","executionInfo":{"status":"error","timestamp":1737609670652,"user_tz":480,"elapsed":131,"user":{"displayName":"Derek Wang","userId":"17638404841155353790"}},"outputId":"f13a0dbf-ad56-4612-e419-a337fd8d3361"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'unique_class' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-b166d1c508b3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseModel0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbaseModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'unique_class' is not defined"]}]},{"cell_type":"markdown","source":["## 1.3 loss and optimizer"],"metadata":{"id":"GwrCLXKnm98Q"}},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(params = baseModel.parameters(), lr = 0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"CWbQ3Jsim26F","executionInfo":{"status":"error","timestamp":1737609706365,"user_tz":480,"elapsed":173,"user":{"displayName":"Derek Wang","userId":"17638404841155353790"}},"outputId":"99e48423-ceed-46b2-8573-3fb864046a90"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'baseModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-597cc490e594>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'baseModel' is not defined"]}]},{"cell_type":"markdown","source":["## 1.4 Functionizing training and testing loops"],"metadata":{"id":"7058snCwnCFG"}},{"cell_type":"code","source":["def training(model: nn.Module,\n","            loader: torch.utils.data.DataLoader,\n","            loss_fn: nn.Module,\n","            optimizer: torch.optim.Optimizer,\n","            epoch: int,\n","            device_on: torch.device = device):\n","\n","    train_loss = 0\n","\n","    model.to(device_on)\n","\n","    for batch, (X,y) in enumerate(loader):\n","\n","        X, y = X.to(device_on), y.to(device_on)\n","\n","        y_pred = model(X)\n","\n","        loss = loss_fn(y_pred, y)\n","        train_loss+=loss\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    train_loss = train_loss/len(loader)\n","    if (epoch % 10 == 0):\n","        print(f\"Epoch: {epoch} | Train Loss: {train_loss: .6f}\")\n","\n","def testing(loader: torch.utils.data.DataLoader,\n","           model: nn.Module,\n","           loss_fn: nn.Module,\n","           device_on: torch.device = device):\n","\n","    test_loss = 0\n","    model.to(device)\n","\n","    model.eval()\n","\n","    with torch.inference_mode():\n","        for X, y in loader:\n","            X,y = X.to(device), y.to(device)\n","\n","            test_pred = model(X)\n","\n","            test_loss+=loss_fn(test_pred, y)\n","\n","        test_loss /= len(loader)\n","\n","        if (epoch % 10 == 0):\n","            print(f\"Test Loss: {test_loss: .6f}\")\n"],"metadata":{"id":"c5CECoNqm_mb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.5 Training and Testing¶¶"],"metadata":{"id":"wj7yor6knFwg"}},{"cell_type":"code","source":["# torch.manual_seed(42)\n","\n","# start_time = timer()\n","\n","# epochs = 50\n","\n","# for epoch in range(epochs):\n","\n","#     training(baseModel, training_loader, loss_fn = loss,\n","#             optimizer = optimizer, epoch = epoch)\n","\n","#     testing(testing_loader, baseModel, loss_fn = loss)\n","\n","# end_time = timer()\n","\n","# total_time = train_time(start_time, end_time, device = device)"],"metadata":{"id":"0XK9aBtlnDLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp  /content/\"Pneumonia & Tuberculosis with Normal & Non-X-ray\" /content/Chest_Multiclass_Classification/"],"metadata":{"id":"ZpaCOOG6nHa4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737677213358,"user_tz":480,"elapsed":1029,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"eb372bba-0906-4527-b044-3187e145c266"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/Pneumonia & Tuberculosis with Normal & Non-X-ray': No such file or directory\n"]}]},{"cell_type":"code","source":["!ls /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrLgpQ3cnS-j","executionInfo":{"status":"ok","timestamp":1737677429652,"user_tz":480,"elapsed":1026,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"0a8f6c38-fced-42fc-972c-a6b5ba7fbaac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chest_Multiclass_Classification  sample_data\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"VzwjDRLJnsNa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737680488425,"user_tz":480,"elapsed":19968,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"69488d42-2487-4f0f-e4c5-8ae8558bf975"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/GerGerGai/Chest_Multiclass_Classification.git"],"metadata":{"id":"uWy-SLmepQay","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737680494866,"user_tz":480,"elapsed":1014,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"669195b6-d4c7-43af-988f-b7b626ac423d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Chest_Multiclass_Classification'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (3/3), done.\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/MLModels.ipynb /content/Chest_Multiclass_Classification/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VuL8bKU1Bpl","executionInfo":{"status":"ok","timestamp":1737680603434,"user_tz":480,"elapsed":304,"user":{"displayName":"Jerry Gai","userId":"03659620442440945758"}},"outputId":"2443774d-125c-4c04-dfcd-ecf1494d7605"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n","cp: cannot stat 'Notebooks/MLModels.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vAcd9UJR1Uj0"},"execution_count":null,"outputs":[]}]}